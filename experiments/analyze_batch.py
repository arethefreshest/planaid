#!/usr/bin/env python3
"""
Analyze and visualize batch test results from run_batch.py.

This script processes the summary_metrics.csv files generated by run_batch.py
and creates visualizations for the PlanAid report.
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging
from datetime import datetime
import numpy as np
from matplotlib_venn import venn3

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def find_latest_batch() -> Path:
    """Find the most recent batch results directory."""
    base_dir = Path(__file__).parent
    results_dir = base_dir / "results"
    
    # Get all batch directories
    batch_dirs = [d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith("batch_")]
    if not batch_dirs:
        raise FileNotFoundError("No batch directories found in results/")
    
    # Sort by creation time and get the latest
    latest_batch = max(batch_dirs, key=lambda d: d.stat().st_mtime)
    logger.info(f"Using latest batch directory: {latest_batch}")
    return latest_batch

def load_metrics(batch_dir: Path) -> pd.DataFrame:
    """Load and process the summary metrics CSV file."""
    metrics_file = batch_dir / "summary_metrics.csv"
    if not metrics_file.exists():
        raise FileNotFoundError(f"Metrics file not found: {metrics_file}")
    
    df = pd.read_csv(metrics_file)
    logger.info(f"Loaded metrics for {len(df)} cases")
    return df

def create_plots(df: pd.DataFrame, output_dir: Path):
    """Generate all required plots."""
    # Create output directory
    plots_dir = output_dir / "summary_plots"
    plots_dir.mkdir(exist_ok=True)
    
    # 1. Bar chart of matching vs non-matching fields
    plt.figure(figsize=(12, 6))
    df['total_fields'] = df['matching_fields'] + df['only_in_bestemmelser'] + df['only_in_plankart'] + df['only_in_sosi']
    df_sorted = df.sort_values('total_fields', ascending=False)
    
    x = np.arange(len(df_sorted))
    width = 0.2
    
    plt.bar(x - width*1.5, df_sorted['matching_fields'], width, label='Matching')
    plt.bar(x - width/2, df_sorted['only_in_bestemmelser'], width, label='Only in Bestemmelser')
    plt.bar(x + width/2, df_sorted['only_in_plankart'], width, label='Only in Plankart')
    plt.bar(x + width*1.5, df_sorted['only_in_sosi'], width, label='Only in SOSI')
    
    plt.xlabel('Case')
    plt.ylabel('Number of Fields')
    plt.title('Field Distribution Across Cases')
    plt.xticks(x, df_sorted['case'], rotation=45, ha='right')
    plt.legend()
    plt.tight_layout()
    plt.savefig(plots_dir / 'fields_barplot.png')
    plt.close()
    
    # 2. Boxplot of processing times
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=df, y='processing_time')
    plt.title('Processing Time Distribution')
    plt.ylabel('Time (seconds)')
    plt.tight_layout()
    plt.savefig(plots_dir / 'timing_boxplot.png')
    plt.close()
    
    # 3. Venn diagram (using aggregated data)
    total_matching = df['matching_fields'].sum()
    total_bestemmelser = df['only_in_bestemmelser'].sum()
    total_plankart = df['only_in_plankart'].sum()
    total_sosi = df['only_in_sosi'].sum()
    
    plt.figure(figsize=(10, 8))
    v = venn3(subsets=(total_bestemmelser, total_plankart, total_matching,
                      total_sosi, 0, 0, 0),
              set_labels=('Bestemmelser', 'Plankart', 'SOSI'))
    plt.title('Field Overlap Between Document Types')
    plt.savefig(plots_dir / 'venn_diagram.png')
    plt.close()

def print_summary(df: pd.DataFrame):
    """Print a textual summary of the results."""
    print("\n=== Batch Test Summary ===")
    print(f"Total cases: {len(df)}")
    print(f"Average processing time: {df['processing_time'].mean():.2f} seconds")
    print(f"Total consistent cases: {df['is_consistent'].sum()}")
    
    # Find case with most mismatches
    df['total_mismatches'] = df['only_in_bestemmelser'] + df['only_in_plankart'] + df['only_in_sosi']
    worst_case = df.loc[df['total_mismatches'].idxmax()]
    print(f"\nCase with most mismatches: {worst_case['case']}")
    print(f"  - Mismatches: {worst_case['total_mismatches']}")
    print(f"  - Processing time: {worst_case['processing_time']:.2f} seconds")
    print(f"  - Consistent: {'Yes' if worst_case['is_consistent'] else 'No'}")

def main():
    try:
        # Find and load the latest batch results
        batch_dir = find_latest_batch()
        df = load_metrics(batch_dir)
        
        # Generate plots
        create_plots(df, batch_dir)
        
        # Print summary
        print_summary(df)
        
        logger.info("Analysis complete!")
        
    except Exception as e:
        logger.error(f"Error during analysis: {str(e)}")
        raise

if __name__ == "__main__":
    main() 